{
  "best_global_step": 13500,
  "best_metric": 1.1281033754348755,
  "best_model_checkpoint": "./seq2seq_model_opus-mt-en-fr/checkpoint-13500",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 13500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.022222222222222223,
      "grad_norm": 3.102177143096924,
      "learning_rate": 9.900000000000002e-06,
      "loss": 1.301707763671875,
      "step": 100
    },
    {
      "epoch": 0.044444444444444446,
      "grad_norm": 3.3811352252960205,
      "learning_rate": 1.9900000000000003e-05,
      "loss": 1.2209221649169921,
      "step": 200
    },
    {
      "epoch": 0.06666666666666667,
      "grad_norm": 2.6989028453826904,
      "learning_rate": 2.9900000000000002e-05,
      "loss": 1.2323763275146484,
      "step": 300
    },
    {
      "epoch": 0.08888888888888889,
      "grad_norm": 3.2649903297424316,
      "learning_rate": 3.99e-05,
      "loss": 1.2227055358886718,
      "step": 400
    },
    {
      "epoch": 0.1111111111111111,
      "grad_norm": 3.4021544456481934,
      "learning_rate": 4.99e-05,
      "loss": 1.1878041076660155,
      "step": 500
    },
    {
      "epoch": 0.1111111111111111,
      "eval_loss": 1.1707264184951782,
      "eval_runtime": 6.5644,
      "eval_samples_per_second": 1218.702,
      "eval_steps_per_second": 76.169,
      "step": 500
    },
    {
      "epoch": 0.13333333333333333,
      "grad_norm": 2.6330454349517822,
      "learning_rate": 4.961923076923077e-05,
      "loss": 1.2246813201904296,
      "step": 600
    },
    {
      "epoch": 0.15555555555555556,
      "grad_norm": 2.808873414993286,
      "learning_rate": 4.923461538461539e-05,
      "loss": 1.2312855529785156,
      "step": 700
    },
    {
      "epoch": 0.17777777777777778,
      "grad_norm": 3.1007134914398193,
      "learning_rate": 4.885e-05,
      "loss": 1.2190003204345703,
      "step": 800
    },
    {
      "epoch": 0.2,
      "grad_norm": 3.5853965282440186,
      "learning_rate": 4.8465384615384616e-05,
      "loss": 1.2121304321289061,
      "step": 900
    },
    {
      "epoch": 0.2222222222222222,
      "grad_norm": 3.8245630264282227,
      "learning_rate": 4.808076923076924e-05,
      "loss": 1.2210868072509766,
      "step": 1000
    },
    {
      "epoch": 0.2222222222222222,
      "eval_loss": 1.1792902946472168,
      "eval_runtime": 6.5868,
      "eval_samples_per_second": 1214.544,
      "eval_steps_per_second": 75.909,
      "step": 1000
    },
    {
      "epoch": 0.24444444444444444,
      "grad_norm": 3.5169270038604736,
      "learning_rate": 4.7696153846153846e-05,
      "loss": 1.2594926452636719,
      "step": 1100
    },
    {
      "epoch": 0.26666666666666666,
      "grad_norm": 2.826838970184326,
      "learning_rate": 4.731153846153846e-05,
      "loss": 1.2302304077148438,
      "step": 1200
    },
    {
      "epoch": 0.28888888888888886,
      "grad_norm": 2.9784700870513916,
      "learning_rate": 4.692692307692308e-05,
      "loss": 1.2274107360839843,
      "step": 1300
    },
    {
      "epoch": 0.3111111111111111,
      "grad_norm": 3.1608266830444336,
      "learning_rate": 4.65423076923077e-05,
      "loss": 1.2284642791748046,
      "step": 1400
    },
    {
      "epoch": 0.3333333333333333,
      "grad_norm": 3.0758464336395264,
      "learning_rate": 4.6157692307692306e-05,
      "loss": 1.2196603393554688,
      "step": 1500
    },
    {
      "epoch": 0.3333333333333333,
      "eval_loss": 1.1651215553283691,
      "eval_runtime": 6.6251,
      "eval_samples_per_second": 1207.523,
      "eval_steps_per_second": 75.47,
      "step": 1500
    },
    {
      "epoch": 0.35555555555555557,
      "grad_norm": 3.281383514404297,
      "learning_rate": 4.577307692307692e-05,
      "loss": 1.2488562774658203,
      "step": 1600
    },
    {
      "epoch": 0.37777777777777777,
      "grad_norm": 3.4204676151275635,
      "learning_rate": 4.538846153846154e-05,
      "loss": 1.2166793060302734,
      "step": 1700
    },
    {
      "epoch": 0.4,
      "grad_norm": 3.120100259780884,
      "learning_rate": 4.500384615384616e-05,
      "loss": 1.2347288513183594,
      "step": 1800
    },
    {
      "epoch": 0.4222222222222222,
      "grad_norm": 2.958232879638672,
      "learning_rate": 4.4619230769230765e-05,
      "loss": 1.2310614776611328,
      "step": 1900
    },
    {
      "epoch": 0.4444444444444444,
      "grad_norm": 3.286170721054077,
      "learning_rate": 4.423461538461539e-05,
      "loss": 1.2043508911132812,
      "step": 2000
    },
    {
      "epoch": 0.4444444444444444,
      "eval_loss": 1.1641030311584473,
      "eval_runtime": 6.5178,
      "eval_samples_per_second": 1227.405,
      "eval_steps_per_second": 76.713,
      "step": 2000
    },
    {
      "epoch": 0.4666666666666667,
      "grad_norm": 2.824159622192383,
      "learning_rate": 4.385e-05,
      "loss": 1.2093274688720703,
      "step": 2100
    },
    {
      "epoch": 0.4888888888888889,
      "grad_norm": 3.431095600128174,
      "learning_rate": 4.346538461538462e-05,
      "loss": 1.2251830291748047,
      "step": 2200
    },
    {
      "epoch": 0.5111111111111111,
      "grad_norm": 2.817357063293457,
      "learning_rate": 4.308076923076923e-05,
      "loss": 1.2138338470458985,
      "step": 2300
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 2.9659578800201416,
      "learning_rate": 4.269615384615385e-05,
      "loss": 1.1963407135009765,
      "step": 2400
    },
    {
      "epoch": 0.5555555555555556,
      "grad_norm": 2.8053407669067383,
      "learning_rate": 4.231153846153846e-05,
      "loss": 1.188717041015625,
      "step": 2500
    },
    {
      "epoch": 0.5555555555555556,
      "eval_loss": 1.161405086517334,
      "eval_runtime": 6.5603,
      "eval_samples_per_second": 1219.46,
      "eval_steps_per_second": 76.216,
      "step": 2500
    },
    {
      "epoch": 0.5777777777777777,
      "grad_norm": 3.415316581726074,
      "learning_rate": 4.192692307692308e-05,
      "loss": 1.2254770660400391,
      "step": 2600
    },
    {
      "epoch": 0.6,
      "grad_norm": 3.0457801818847656,
      "learning_rate": 4.15423076923077e-05,
      "loss": 1.2049606323242188,
      "step": 2700
    },
    {
      "epoch": 0.6222222222222222,
      "grad_norm": 3.331926107406616,
      "learning_rate": 4.1157692307692306e-05,
      "loss": 1.2266325378417968,
      "step": 2800
    },
    {
      "epoch": 0.6444444444444445,
      "grad_norm": 3.1192970275878906,
      "learning_rate": 4.077307692307693e-05,
      "loss": 1.2003639221191407,
      "step": 2900
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 3.6315159797668457,
      "learning_rate": 4.038846153846154e-05,
      "loss": 1.2020309448242188,
      "step": 3000
    },
    {
      "epoch": 0.6666666666666666,
      "eval_loss": 1.1530839204788208,
      "eval_runtime": 6.6713,
      "eval_samples_per_second": 1199.17,
      "eval_steps_per_second": 74.948,
      "step": 3000
    },
    {
      "epoch": 0.6888888888888889,
      "grad_norm": 2.922219753265381,
      "learning_rate": 4.000384615384616e-05,
      "loss": 1.206752700805664,
      "step": 3100
    },
    {
      "epoch": 0.7111111111111111,
      "grad_norm": 2.767717123031616,
      "learning_rate": 3.961923076923077e-05,
      "loss": 1.1892174530029296,
      "step": 3200
    },
    {
      "epoch": 0.7333333333333333,
      "grad_norm": 3.1894338130950928,
      "learning_rate": 3.923461538461539e-05,
      "loss": 1.1861271667480469,
      "step": 3300
    },
    {
      "epoch": 0.7555555555555555,
      "grad_norm": 2.808694362640381,
      "learning_rate": 3.885e-05,
      "loss": 1.2016961669921875,
      "step": 3400
    },
    {
      "epoch": 0.7777777777777778,
      "grad_norm": 3.1737887859344482,
      "learning_rate": 3.846538461538462e-05,
      "loss": 1.2018761444091797,
      "step": 3500
    },
    {
      "epoch": 0.7777777777777778,
      "eval_loss": 1.1478976011276245,
      "eval_runtime": 6.6395,
      "eval_samples_per_second": 1204.907,
      "eval_steps_per_second": 75.307,
      "step": 3500
    },
    {
      "epoch": 0.8,
      "grad_norm": 3.130331039428711,
      "learning_rate": 3.808076923076923e-05,
      "loss": 1.1728852081298828,
      "step": 3600
    },
    {
      "epoch": 0.8222222222222222,
      "grad_norm": 3.243673086166382,
      "learning_rate": 3.769615384615385e-05,
      "loss": 1.197971649169922,
      "step": 3700
    },
    {
      "epoch": 0.8444444444444444,
      "grad_norm": 3.243942975997925,
      "learning_rate": 3.731153846153846e-05,
      "loss": 1.195691375732422,
      "step": 3800
    },
    {
      "epoch": 0.8666666666666667,
      "grad_norm": 3.4816691875457764,
      "learning_rate": 3.6926923076923084e-05,
      "loss": 1.1735997772216797,
      "step": 3900
    },
    {
      "epoch": 0.8888888888888888,
      "grad_norm": 3.3245108127593994,
      "learning_rate": 3.654230769230769e-05,
      "loss": 1.2330361938476562,
      "step": 4000
    },
    {
      "epoch": 0.8888888888888888,
      "eval_loss": 1.1420371532440186,
      "eval_runtime": 6.7203,
      "eval_samples_per_second": 1190.419,
      "eval_steps_per_second": 74.401,
      "step": 4000
    },
    {
      "epoch": 0.9111111111111111,
      "grad_norm": 3.3687546253204346,
      "learning_rate": 3.615769230769231e-05,
      "loss": 1.2038897705078124,
      "step": 4100
    },
    {
      "epoch": 0.9333333333333333,
      "grad_norm": 3.084160566329956,
      "learning_rate": 3.577307692307693e-05,
      "loss": 1.1895662689208983,
      "step": 4200
    },
    {
      "epoch": 0.9555555555555556,
      "grad_norm": 2.938408613204956,
      "learning_rate": 3.538846153846154e-05,
      "loss": 1.1762469482421876,
      "step": 4300
    },
    {
      "epoch": 0.9777777777777777,
      "grad_norm": 2.9179461002349854,
      "learning_rate": 3.500384615384615e-05,
      "loss": 1.19598388671875,
      "step": 4400
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.9851253032684326,
      "learning_rate": 3.461923076923077e-05,
      "loss": 1.205620574951172,
      "step": 4500
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.1390820741653442,
      "eval_runtime": 6.6131,
      "eval_samples_per_second": 1209.723,
      "eval_steps_per_second": 75.608,
      "step": 4500
    },
    {
      "epoch": 1.0222222222222221,
      "grad_norm": 2.8768420219421387,
      "learning_rate": 3.423461538461539e-05,
      "loss": 1.014015655517578,
      "step": 4600
    },
    {
      "epoch": 1.0444444444444445,
      "grad_norm": 2.8813953399658203,
      "learning_rate": 3.385e-05,
      "loss": 1.0115351104736328,
      "step": 4700
    },
    {
      "epoch": 1.0666666666666667,
      "grad_norm": 3.347348690032959,
      "learning_rate": 3.346538461538462e-05,
      "loss": 1.0317597198486328,
      "step": 4800
    },
    {
      "epoch": 1.0888888888888888,
      "grad_norm": 3.0649654865264893,
      "learning_rate": 3.308076923076923e-05,
      "loss": 1.0261248016357423,
      "step": 4900
    },
    {
      "epoch": 1.1111111111111112,
      "grad_norm": 3.4749107360839844,
      "learning_rate": 3.269615384615385e-05,
      "loss": 1.0624286651611328,
      "step": 5000
    },
    {
      "epoch": 1.1111111111111112,
      "eval_loss": 1.1444916725158691,
      "eval_runtime": 6.577,
      "eval_samples_per_second": 1216.351,
      "eval_steps_per_second": 76.022,
      "step": 5000
    },
    {
      "epoch": 1.1333333333333333,
      "grad_norm": 3.374164342880249,
      "learning_rate": 3.231153846153846e-05,
      "loss": 1.0531564331054688,
      "step": 5100
    },
    {
      "epoch": 1.1555555555555554,
      "grad_norm": 3.0130245685577393,
      "learning_rate": 3.192692307692308e-05,
      "loss": 1.0163605499267578,
      "step": 5200
    },
    {
      "epoch": 1.1777777777777778,
      "grad_norm": 2.8500051498413086,
      "learning_rate": 3.154230769230769e-05,
      "loss": 1.0416109466552734,
      "step": 5300
    },
    {
      "epoch": 1.2,
      "grad_norm": 3.220823049545288,
      "learning_rate": 3.115769230769231e-05,
      "loss": 1.036213150024414,
      "step": 5400
    },
    {
      "epoch": 1.2222222222222223,
      "grad_norm": 3.5165445804595947,
      "learning_rate": 3.077307692307693e-05,
      "loss": 1.0151824951171875,
      "step": 5500
    },
    {
      "epoch": 1.2222222222222223,
      "eval_loss": 1.1453709602355957,
      "eval_runtime": 6.6114,
      "eval_samples_per_second": 1210.031,
      "eval_steps_per_second": 75.627,
      "step": 5500
    },
    {
      "epoch": 1.2444444444444445,
      "grad_norm": 3.640702724456787,
      "learning_rate": 3.0388461538461537e-05,
      "loss": 1.033661880493164,
      "step": 5600
    },
    {
      "epoch": 1.2666666666666666,
      "grad_norm": 3.4628944396972656,
      "learning_rate": 3.0003846153846155e-05,
      "loss": 1.010765609741211,
      "step": 5700
    },
    {
      "epoch": 1.2888888888888888,
      "grad_norm": 2.7087950706481934,
      "learning_rate": 2.961923076923077e-05,
      "loss": 1.0376821899414062,
      "step": 5800
    },
    {
      "epoch": 1.3111111111111111,
      "grad_norm": 3.7310101985931396,
      "learning_rate": 2.923461538461539e-05,
      "loss": 1.03302734375,
      "step": 5900
    },
    {
      "epoch": 1.3333333333333333,
      "grad_norm": 3.2009012699127197,
      "learning_rate": 2.885e-05,
      "loss": 1.0292047119140626,
      "step": 6000
    },
    {
      "epoch": 1.3333333333333333,
      "eval_loss": 1.1412605047225952,
      "eval_runtime": 6.612,
      "eval_samples_per_second": 1209.918,
      "eval_steps_per_second": 75.62,
      "step": 6000
    },
    {
      "epoch": 1.3555555555555556,
      "grad_norm": 3.002763509750366,
      "learning_rate": 2.8465384615384615e-05,
      "loss": 1.0261260223388673,
      "step": 6100
    },
    {
      "epoch": 1.3777777777777778,
      "grad_norm": 2.9617507457733154,
      "learning_rate": 2.8080769230769233e-05,
      "loss": 1.012212905883789,
      "step": 6200
    },
    {
      "epoch": 1.4,
      "grad_norm": 2.7343039512634277,
      "learning_rate": 2.7696153846153848e-05,
      "loss": 1.0500901794433595,
      "step": 6300
    },
    {
      "epoch": 1.4222222222222223,
      "grad_norm": 2.745997667312622,
      "learning_rate": 2.731153846153846e-05,
      "loss": 1.0629059600830078,
      "step": 6400
    },
    {
      "epoch": 1.4444444444444444,
      "grad_norm": 3.1952908039093018,
      "learning_rate": 2.6926923076923078e-05,
      "loss": 1.0462057495117187,
      "step": 6500
    },
    {
      "epoch": 1.4444444444444444,
      "eval_loss": 1.1397086381912231,
      "eval_runtime": 6.7869,
      "eval_samples_per_second": 1178.733,
      "eval_steps_per_second": 73.671,
      "step": 6500
    },
    {
      "epoch": 1.4666666666666668,
      "grad_norm": 2.6417489051818848,
      "learning_rate": 2.6542307692307693e-05,
      "loss": 1.0350348663330078,
      "step": 6600
    },
    {
      "epoch": 1.488888888888889,
      "grad_norm": 3.194457769393921,
      "learning_rate": 2.615769230769231e-05,
      "loss": 1.0300547790527343,
      "step": 6700
    },
    {
      "epoch": 1.511111111111111,
      "grad_norm": 3.0778415203094482,
      "learning_rate": 2.5773076923076922e-05,
      "loss": 1.0331735229492187,
      "step": 6800
    },
    {
      "epoch": 1.5333333333333332,
      "grad_norm": 3.412839412689209,
      "learning_rate": 2.5388461538461537e-05,
      "loss": 1.0395758056640625,
      "step": 6900
    },
    {
      "epoch": 1.5555555555555556,
      "grad_norm": 3.0882790088653564,
      "learning_rate": 2.5003846153846156e-05,
      "loss": 1.0088102722167969,
      "step": 7000
    },
    {
      "epoch": 1.5555555555555556,
      "eval_loss": 1.139184832572937,
      "eval_runtime": 6.6845,
      "eval_samples_per_second": 1196.803,
      "eval_steps_per_second": 74.8,
      "step": 7000
    },
    {
      "epoch": 1.5777777777777777,
      "grad_norm": 2.6187665462493896,
      "learning_rate": 2.461923076923077e-05,
      "loss": 1.0501081848144531,
      "step": 7100
    },
    {
      "epoch": 1.6,
      "grad_norm": 3.454557180404663,
      "learning_rate": 2.4234615384615385e-05,
      "loss": 1.0353929901123047,
      "step": 7200
    },
    {
      "epoch": 1.6222222222222222,
      "grad_norm": 2.8897578716278076,
      "learning_rate": 2.385e-05,
      "loss": 1.0216740417480468,
      "step": 7300
    },
    {
      "epoch": 1.6444444444444444,
      "grad_norm": 3.3654696941375732,
      "learning_rate": 2.3465384615384615e-05,
      "loss": 1.0316070556640624,
      "step": 7400
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 3.1645312309265137,
      "learning_rate": 2.308076923076923e-05,
      "loss": 1.0409454345703124,
      "step": 7500
    },
    {
      "epoch": 1.6666666666666665,
      "eval_loss": 1.134857177734375,
      "eval_runtime": 7.0345,
      "eval_samples_per_second": 1137.259,
      "eval_steps_per_second": 71.079,
      "step": 7500
    },
    {
      "epoch": 1.6888888888888889,
      "grad_norm": 3.0058836936950684,
      "learning_rate": 2.269615384615385e-05,
      "loss": 1.0477296447753905,
      "step": 7600
    },
    {
      "epoch": 1.7111111111111112,
      "grad_norm": 2.896503210067749,
      "learning_rate": 2.231153846153846e-05,
      "loss": 1.0243357086181641,
      "step": 7700
    },
    {
      "epoch": 1.7333333333333334,
      "grad_norm": 3.046039342880249,
      "learning_rate": 2.1926923076923078e-05,
      "loss": 1.031569366455078,
      "step": 7800
    },
    {
      "epoch": 1.7555555555555555,
      "grad_norm": 3.1734001636505127,
      "learning_rate": 2.1542307692307693e-05,
      "loss": 1.074782257080078,
      "step": 7900
    },
    {
      "epoch": 1.7777777777777777,
      "grad_norm": 3.4371912479400635,
      "learning_rate": 2.1157692307692308e-05,
      "loss": 1.024348831176758,
      "step": 8000
    },
    {
      "epoch": 1.7777777777777777,
      "eval_loss": 1.1335607767105103,
      "eval_runtime": 6.6314,
      "eval_samples_per_second": 1206.381,
      "eval_steps_per_second": 75.399,
      "step": 8000
    },
    {
      "epoch": 1.8,
      "grad_norm": 3.6303136348724365,
      "learning_rate": 2.0773076923076923e-05,
      "loss": 1.0598834228515626,
      "step": 8100
    },
    {
      "epoch": 1.8222222222222222,
      "grad_norm": 2.9139814376831055,
      "learning_rate": 2.038846153846154e-05,
      "loss": 1.0381853485107422,
      "step": 8200
    },
    {
      "epoch": 1.8444444444444446,
      "grad_norm": 2.9334144592285156,
      "learning_rate": 2.0003846153846153e-05,
      "loss": 1.0273304748535157,
      "step": 8300
    },
    {
      "epoch": 1.8666666666666667,
      "grad_norm": 3.3584814071655273,
      "learning_rate": 1.961923076923077e-05,
      "loss": 1.0458722686767579,
      "step": 8400
    },
    {
      "epoch": 1.8888888888888888,
      "grad_norm": 2.8918325901031494,
      "learning_rate": 1.9234615384615386e-05,
      "loss": 1.023924331665039,
      "step": 8500
    },
    {
      "epoch": 1.8888888888888888,
      "eval_loss": 1.1324224472045898,
      "eval_runtime": 6.639,
      "eval_samples_per_second": 1205.0,
      "eval_steps_per_second": 75.312,
      "step": 8500
    },
    {
      "epoch": 1.911111111111111,
      "grad_norm": 2.8477895259857178,
      "learning_rate": 1.885e-05,
      "loss": 1.0276227569580079,
      "step": 8600
    },
    {
      "epoch": 1.9333333333333333,
      "grad_norm": 3.2062580585479736,
      "learning_rate": 1.8465384615384616e-05,
      "loss": 1.0522909545898438,
      "step": 8700
    },
    {
      "epoch": 1.9555555555555557,
      "grad_norm": 2.8710873126983643,
      "learning_rate": 1.808076923076923e-05,
      "loss": 1.0327055358886719,
      "step": 8800
    },
    {
      "epoch": 1.9777777777777779,
      "grad_norm": 2.7831246852874756,
      "learning_rate": 1.7696153846153845e-05,
      "loss": 1.009088134765625,
      "step": 8900
    },
    {
      "epoch": 2.0,
      "grad_norm": 2.905684232711792,
      "learning_rate": 1.7311538461538464e-05,
      "loss": 1.040724639892578,
      "step": 9000
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.1285114288330078,
      "eval_runtime": 6.6625,
      "eval_samples_per_second": 1200.754,
      "eval_steps_per_second": 75.047,
      "step": 9000
    },
    {
      "epoch": 2.022222222222222,
      "grad_norm": 2.977407217025757,
      "learning_rate": 1.692692307692308e-05,
      "loss": 0.9388581085205078,
      "step": 9100
    },
    {
      "epoch": 2.0444444444444443,
      "grad_norm": 2.879133701324463,
      "learning_rate": 1.6542307692307694e-05,
      "loss": 0.9163771820068359,
      "step": 9200
    },
    {
      "epoch": 2.066666666666667,
      "grad_norm": 2.7637317180633545,
      "learning_rate": 1.615769230769231e-05,
      "loss": 0.9387991333007812,
      "step": 9300
    },
    {
      "epoch": 2.088888888888889,
      "grad_norm": 3.181164026260376,
      "learning_rate": 1.5773076923076923e-05,
      "loss": 0.9051462554931641,
      "step": 9400
    },
    {
      "epoch": 2.111111111111111,
      "grad_norm": 3.2590696811676025,
      "learning_rate": 1.538846153846154e-05,
      "loss": 0.8979785919189454,
      "step": 9500
    },
    {
      "epoch": 2.111111111111111,
      "eval_loss": 1.1369402408599854,
      "eval_runtime": 6.6594,
      "eval_samples_per_second": 1201.316,
      "eval_steps_per_second": 75.082,
      "step": 9500
    },
    {
      "epoch": 2.1333333333333333,
      "grad_norm": 3.0059256553649902,
      "learning_rate": 1.5003846153846155e-05,
      "loss": 0.9289620208740235,
      "step": 9600
    },
    {
      "epoch": 2.1555555555555554,
      "grad_norm": 2.721177816390991,
      "learning_rate": 1.4619230769230771e-05,
      "loss": 0.917364501953125,
      "step": 9700
    },
    {
      "epoch": 2.1777777777777776,
      "grad_norm": 2.6677284240722656,
      "learning_rate": 1.4234615384615385e-05,
      "loss": 0.9210133361816406,
      "step": 9800
    },
    {
      "epoch": 2.2,
      "grad_norm": 2.9467663764953613,
      "learning_rate": 1.3850000000000001e-05,
      "loss": 0.9176214599609375,
      "step": 9900
    },
    {
      "epoch": 2.2222222222222223,
      "grad_norm": 2.9495580196380615,
      "learning_rate": 1.3465384615384616e-05,
      "loss": 0.926318130493164,
      "step": 10000
    },
    {
      "epoch": 2.2222222222222223,
      "eval_loss": 1.134821891784668,
      "eval_runtime": 6.6208,
      "eval_samples_per_second": 1208.312,
      "eval_steps_per_second": 75.52,
      "step": 10000
    },
    {
      "epoch": 2.2444444444444445,
      "grad_norm": 2.887024402618408,
      "learning_rate": 1.3080769230769233e-05,
      "loss": 0.9256573486328125,
      "step": 10100
    },
    {
      "epoch": 2.2666666666666666,
      "grad_norm": 2.9505438804626465,
      "learning_rate": 1.2696153846153846e-05,
      "loss": 0.9001555633544922,
      "step": 10200
    },
    {
      "epoch": 2.2888888888888888,
      "grad_norm": 2.7283213138580322,
      "learning_rate": 1.2311538461538463e-05,
      "loss": 0.8951841735839844,
      "step": 10300
    },
    {
      "epoch": 2.311111111111111,
      "grad_norm": 2.6277921199798584,
      "learning_rate": 1.1926923076923077e-05,
      "loss": 0.923657455444336,
      "step": 10400
    },
    {
      "epoch": 2.3333333333333335,
      "grad_norm": 2.581331968307495,
      "learning_rate": 1.1542307692307692e-05,
      "loss": 0.9321089172363282,
      "step": 10500
    },
    {
      "epoch": 2.3333333333333335,
      "eval_loss": 1.1345093250274658,
      "eval_runtime": 6.6176,
      "eval_samples_per_second": 1208.889,
      "eval_steps_per_second": 75.556,
      "step": 10500
    },
    {
      "epoch": 2.3555555555555556,
      "grad_norm": 3.0067250728607178,
      "learning_rate": 1.1157692307692307e-05,
      "loss": 0.8979461669921875,
      "step": 10600
    },
    {
      "epoch": 2.3777777777777778,
      "grad_norm": 2.998619318008423,
      "learning_rate": 1.0773076923076924e-05,
      "loss": 0.913414077758789,
      "step": 10700
    },
    {
      "epoch": 2.4,
      "grad_norm": 2.704773187637329,
      "learning_rate": 1.0388461538461539e-05,
      "loss": 0.9236087799072266,
      "step": 10800
    },
    {
      "epoch": 2.422222222222222,
      "grad_norm": 3.1665310859680176,
      "learning_rate": 1.0003846153846154e-05,
      "loss": 0.9095687103271485,
      "step": 10900
    },
    {
      "epoch": 2.4444444444444446,
      "grad_norm": 2.6748645305633545,
      "learning_rate": 9.619230769230768e-06,
      "loss": 0.9333347320556641,
      "step": 11000
    },
    {
      "epoch": 2.4444444444444446,
      "eval_loss": 1.1337034702301025,
      "eval_runtime": 6.6171,
      "eval_samples_per_second": 1208.982,
      "eval_steps_per_second": 75.561,
      "step": 11000
    },
    {
      "epoch": 2.466666666666667,
      "grad_norm": 3.0095901489257812,
      "learning_rate": 9.234615384615385e-06,
      "loss": 0.9262718200683594,
      "step": 11100
    },
    {
      "epoch": 2.488888888888889,
      "grad_norm": 3.332108497619629,
      "learning_rate": 8.85e-06,
      "loss": 0.9302385711669922,
      "step": 11200
    },
    {
      "epoch": 2.511111111111111,
      "grad_norm": 2.952638864517212,
      "learning_rate": 8.465384615384615e-06,
      "loss": 0.9246133422851562,
      "step": 11300
    },
    {
      "epoch": 2.533333333333333,
      "grad_norm": 3.1900925636291504,
      "learning_rate": 8.080769230769231e-06,
      "loss": 0.9333600616455078,
      "step": 11400
    },
    {
      "epoch": 2.5555555555555554,
      "grad_norm": 2.8824615478515625,
      "learning_rate": 7.696153846153846e-06,
      "loss": 0.9156478118896484,
      "step": 11500
    },
    {
      "epoch": 2.5555555555555554,
      "eval_loss": 1.132120132446289,
      "eval_runtime": 6.6034,
      "eval_samples_per_second": 1211.501,
      "eval_steps_per_second": 75.719,
      "step": 11500
    },
    {
      "epoch": 2.5777777777777775,
      "grad_norm": 3.0819315910339355,
      "learning_rate": 7.311538461538461e-06,
      "loss": 0.9081471252441407,
      "step": 11600
    },
    {
      "epoch": 2.6,
      "grad_norm": 3.0204427242279053,
      "learning_rate": 6.926923076923077e-06,
      "loss": 0.9214387512207032,
      "step": 11700
    },
    {
      "epoch": 2.6222222222222222,
      "grad_norm": 3.4817445278167725,
      "learning_rate": 6.542307692307692e-06,
      "loss": 0.9153406524658203,
      "step": 11800
    },
    {
      "epoch": 2.6444444444444444,
      "grad_norm": 2.7529942989349365,
      "learning_rate": 6.1576923076923085e-06,
      "loss": 0.9252877044677734,
      "step": 11900
    },
    {
      "epoch": 2.6666666666666665,
      "grad_norm": 2.8833236694335938,
      "learning_rate": 5.773076923076923e-06,
      "loss": 0.9249570465087891,
      "step": 12000
    },
    {
      "epoch": 2.6666666666666665,
      "eval_loss": 1.1306086778640747,
      "eval_runtime": 6.8422,
      "eval_samples_per_second": 1169.208,
      "eval_steps_per_second": 73.076,
      "step": 12000
    },
    {
      "epoch": 2.688888888888889,
      "grad_norm": 2.8815724849700928,
      "learning_rate": 5.388461538461539e-06,
      "loss": 0.9075933837890625,
      "step": 12100
    },
    {
      "epoch": 2.7111111111111112,
      "grad_norm": 2.9658796787261963,
      "learning_rate": 5.003846153846154e-06,
      "loss": 0.9480460357666015,
      "step": 12200
    },
    {
      "epoch": 2.7333333333333334,
      "grad_norm": 2.842068910598755,
      "learning_rate": 4.61923076923077e-06,
      "loss": 0.9142147827148438,
      "step": 12300
    },
    {
      "epoch": 2.7555555555555555,
      "grad_norm": 2.9958903789520264,
      "learning_rate": 4.234615384615385e-06,
      "loss": 0.899176254272461,
      "step": 12400
    },
    {
      "epoch": 2.7777777777777777,
      "grad_norm": 2.966184139251709,
      "learning_rate": 3.85e-06,
      "loss": 0.9369874572753907,
      "step": 12500
    },
    {
      "epoch": 2.7777777777777777,
      "eval_loss": 1.1285712718963623,
      "eval_runtime": 6.6406,
      "eval_samples_per_second": 1204.705,
      "eval_steps_per_second": 75.294,
      "step": 12500
    },
    {
      "epoch": 2.8,
      "grad_norm": 3.301318645477295,
      "learning_rate": 3.4653846153846153e-06,
      "loss": 0.9331019592285156,
      "step": 12600
    },
    {
      "epoch": 2.822222222222222,
      "grad_norm": 2.7616748809814453,
      "learning_rate": 3.0807692307692306e-06,
      "loss": 0.9256542205810547,
      "step": 12700
    },
    {
      "epoch": 2.8444444444444446,
      "grad_norm": 2.983893632888794,
      "learning_rate": 2.6961538461538464e-06,
      "loss": 0.9245927429199219,
      "step": 12800
    },
    {
      "epoch": 2.8666666666666667,
      "grad_norm": 2.8926634788513184,
      "learning_rate": 2.3115384615384617e-06,
      "loss": 0.9060162353515625,
      "step": 12900
    },
    {
      "epoch": 2.888888888888889,
      "grad_norm": 2.7166218757629395,
      "learning_rate": 1.926923076923077e-06,
      "loss": 0.934342041015625,
      "step": 13000
    },
    {
      "epoch": 2.888888888888889,
      "eval_loss": 1.1284421682357788,
      "eval_runtime": 6.7511,
      "eval_samples_per_second": 1184.986,
      "eval_steps_per_second": 74.062,
      "step": 13000
    },
    {
      "epoch": 2.911111111111111,
      "grad_norm": 3.2342727184295654,
      "learning_rate": 1.5423076923076923e-06,
      "loss": 0.927490234375,
      "step": 13100
    },
    {
      "epoch": 2.9333333333333336,
      "grad_norm": 2.8458480834960938,
      "learning_rate": 1.1576923076923077e-06,
      "loss": 0.916087875366211,
      "step": 13200
    },
    {
      "epoch": 2.9555555555555557,
      "grad_norm": 3.135282039642334,
      "learning_rate": 7.730769230769232e-07,
      "loss": 0.9380245971679687,
      "step": 13300
    },
    {
      "epoch": 2.977777777777778,
      "grad_norm": 2.718214511871338,
      "learning_rate": 3.884615384615385e-07,
      "loss": 0.9421112060546875,
      "step": 13400
    },
    {
      "epoch": 3.0,
      "grad_norm": 3.2021284103393555,
      "learning_rate": 3.846153846153846e-09,
      "loss": 0.913332290649414,
      "step": 13500
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.1281033754348755,
      "eval_runtime": 6.6248,
      "eval_samples_per_second": 1207.575,
      "eval_steps_per_second": 75.473,
      "step": 13500
    }
  ],
  "logging_steps": 100,
  "max_steps": 13500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 7322046824448000.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
